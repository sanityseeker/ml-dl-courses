{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Высокие данные\n",
    "\n",
    "Опять будем решать ту же самую задачу - предсказывать цену по описанию. Однако теперь данных в 2 раза больше - будем считать, что это уже много и пытаться решить эту проблему различными способами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распределенный градиентный спуск\n",
    "\n",
    "Классический алгоритм для оптимизации функции потерь - градиентный спуск. Чтобы посчитать градиентный спуск необходимо подсчитать градиент на каждом объекте выборки и сложить. При этом подсчет градиента на каждом объекта - это независимая операция.\n",
    "\n",
    "Уже видно из описания, что это процесс, который достаточно хорошо ложится на парадигму вычислений в Spark. Рабочие узлы могут параллельно подсчитать градиент, после чего его получит мастер-машина (клиент, который управляет вычислениями), сделает шаг в направлении и разошлет новые веса рабочим. Эти шаги нужно будет повторять, пока градиентный спуск не сойдется.\n",
    "\n",
    "По сути это очень простая версия подхода \"Сервер параметров (Parameter server)\". И она уже реализована в Spark ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName(\"CourseraLocalSpark\").setMaster(\"local[*]\")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DIstributed-ML').getOrCreate()\n",
    "airbnb = spark.read.option(\"header\",True).option(\"delimiter\", \"\\t\").csv('airbnb-200k.tsv')\n",
    "airbnb.createOrReplaceTempView(\"airbnb\")\n",
    "\n",
    "raw_df = spark.sql(\"\"\"\n",
    "    SELECT double(Price), split(Description, ' ') as Words\n",
    "    FROM airbnb\n",
    "    WHERE Description is not Null AND double(Price) is not Null\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем текст через Bag-Of-Words и сразу делим на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"Words\", outputCol=\"Features\")\n",
    "spark_vectorizer = cv.fit(raw_df)\n",
    "X = spark_vectorizer.transform(raw_df)\n",
    "X_train, X_test = X.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|Price|               Words|            Features|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|[\"Spacious, 19th,...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[\"The, accommodat...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[A, bright, chic,...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[A, great, safe, ...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Beautiful, &, Br...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Bedroom, in, 1st...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Charming, and, c...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Cute, exposed, b...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Die, Wohnung, li...|(262144,[5,235,50...|\n",
      "|  0.0|[I, have, a, priv...|(262144,[0,1,2,4,...|\n",
      "|  0.0|[I, have, a, priv...|(262144,[0,1,2,4,...|\n",
      "|  0.0|[Located, on, one...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Marvelous, New, ...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Minimalist, loft...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Private, bedroom...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Private,, separa...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Stay, at, your, ...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[Steps, from, Mis...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[The, entire, ups...|(262144,[0,1,2,3,...|\n",
      "|  0.0|[The, place:, Ama...|(262144,[0,1,2,3,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект линейной регрессии. Указываем, что признаки лежат в колонке Features, а целевая переменная - в Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(featuresCol='Features', labelCol=\"Price\", maxIter=10, regParam=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 ms, sys: 0 ns, total: 15.3 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regressor_model = regressor.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем метрику качества на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-------------------+\n",
      "|Price|               Words|            Features|         prediction|\n",
      "+-----+--------------------+--------------------+-------------------+\n",
      "|  0.0|[A, comfortable,,...|(262144,[0,1,2,3,...|-36.064333580915275|\n",
      "|  0.0|[Die, Wohnung, li...|(262144,[5,89,151...| 54.743880511540596|\n",
      "|  0.0|[I, am, renting, ...|(262144,[0,1,2,3,...| 151.95972634910615|\n",
      "|  0.0|[It, is, a, cozy,...|(262144,[0,1,2,3,...|  47.71575250039061|\n",
      "|  0.0|[It, is, a, new, ...|(262144,[0,1,2,4,...| 140.78350583790393|\n",
      "+-----+--------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = regressor_model.transform(X_test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3197710094091262"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"Price\", metricName=\"r2\")\n",
    "lr_evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, вполне неплохой результат, учитывая, что мы ничего не делали с данными и никак не настраивали дополнительно модель. Это решение может теоретически масштабироваться до того момента, пока данные вообще помещаются на кластере (а это много).\n",
    "\n",
    "Можно ли лучше? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Vowpal Wabbit и Tree Allreduce\n",
    "\n",
    "Уже известный нам инструмент VW позволяет решать задачу не только широких данных, но и высоких через подход Tree Allreduce. \n",
    "\n",
    "По сути своей этот подход похож на то, что мы делали с помощью спарка, однако теперь все вычислительные узлы собраны в дерево, что позволяет тратить гораздо меньше времени на сетевое взаимодействие между узлами.\n",
    "\n",
    "Для работы с VW есть специальная утилита `spanning_tree` - это \"вершина\" дерева и менеджер всего процесса обучения. VW подключается по сети к этому сервису, получает свое место в дереве и начинает считать и обмениваться градиентами согласно схеме. \n",
    "\n",
    "По окончанию обучения, когда все узлы завершат свою работу, один из рабочих может сохранить полученные коэффициенты.\n",
    "\n",
    "Перед тем, как обучать модель, преобразуем данные в формат vw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"airbnb-200k.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_vw(raw_text, target):\n",
    "    word_pattern = re.compile(r\"[a-zA-Z0-9_]+\")\n",
    "    words = []\n",
    "    for match in re.finditer(word_pattern, raw_text.lower()):\n",
    "        words.append(match.group(0))\n",
    "    \n",
    "    if not words: \n",
    "        return None\n",
    "    return \"{} |d {}\".format(float(target), \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Price', \"Description\"], inplace=True)\n",
    "Y = df['Price']\n",
    "X = df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vw(X_data, Y_data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for x, y in zip(X_data, Y_data):\n",
    "            vw_object = convert_to_vw(x, y)\n",
    "            if not vw_object:\n",
    "                continue\n",
    "            f.write(vw_object + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нам нужно руками разделить данные на отдельные части. Каждую часть мы выдадим отдельному рабочему для обработки.\n",
    "\n",
    "Тут важно также понимать, что в реальной жизни мы бы разделили данные сразу между несколькими машинами. И тогда бы данные равномерно распределились и каждый рабочий бы работал параллельно с другими на своей машине.\n",
    "\n",
    "В нашем же окружении мы делаем все на одной машине для наглядности, но нужно держать в голове, что и `spanning_tree` и `vw` для максимально эффективности запускались бы на разным машинах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vw(X_train1, y_train1, \"airbnb-train-part1.vw\")\n",
    "write_vw(X_train2, y_train2, \"airbnb-train-part2.vw\")\n",
    "write_vw(X_test, y_test, \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395.0 |d sunny unique home with a treehouse theme in the center of the bay area s attractions a 15 minute walk get you to the attractions of the castro mission district and soma with public transportation you can quickly get everywhere else if you find ladders levels wood and little nooks fun you are going to love the mission treehouse we treat everyone in the airbnb community regardless of their race religion national origin ethnicity disability sex gender identity sexual orientation or age with respect kindness and compassion and without judgment or bias this is an lgbtqia friendly household about the mission treehouse 2 bedroom and 2 full bathrooms excellent location the mission district near downtown moscone castro soma and the sights parking private attached garage full kitchen wonderful details and decor i have lovingly crafted my 3 story modern condo into a romantic playground of my dreams and i m happy to share it with you both bedrooms h\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb-train-part1.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 |d un precioso piso con cocina y ba o reformados y agradable ambiente habitaci n principal muy amplia con cama matrimonio de 1 60cm sal n con comedor y 2 sof s uno de ellos convertible en cama una habitaci n individual con una cama peque a de 90cm cuarto piso exterior y muy luminoso a solo 20 minutos en autob s del centro de madrid puerta del sol estaci n de metro alto de extremadura l nea 6 en la misma plaza donde se encuentra la vivienda a solo 10 minutos en metro de plaza de espa a y a 5 minutos de pr ncipe p o centro comercial y de ocio shopping cines restaurantes rodeado de zonas verdes casa de campo y lago paseo de avenida de portugal y madrid r o todo el piso estar disponible para cualquier duda o ayuda que pod is necesitar avisando con antelaci n m vil phone number hidden barrio popular con muchos servicios en la misma plaza supermercado d a fruter as bares y cafeter as entrada al metro de madrid a unos pasos del portal de la vivienda varias l neas de a\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb-test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем spanning_tree. Так как мы запускаем его из Jupyter notebook, то есть небольшая особенность - чтобы он правильно запустился в фоне, мы используем команду %%bash и параметром --bg (то есть запуск в фоне). Сам spanning_tree запускаем с --nondaemon потому что сама ячейка благодаря %%bash уже запустится в фоне.\n",
    "\n",
    "На реально машине вы бы использовали просто команду `spanning_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg --out OUT --err ERR\n",
    "spanning_tree --nondaemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, что он запустился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jovyan     447  0.0  0.0   6068  1632 ?        S    21:10   0:00 spanning_tree --nondaemon\n",
      "jovyan     448  0.0  0.0   6896  3276 pts/0    Ss+  21:10   0:00 /bin/bash -c  ps aux | grep spanning_tree\n",
      "jovyan     450  0.0  0.0   6436   660 pts/0    S+   21:10   0:00 grep spanning_tree\n"
     ]
    }
   ],
   "source": [
    "! ps aux | grep spanning_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим работающий процесс, значит все хорошо. \n",
    "\n",
    "Теперь давайте запускать рабочих. Для этого используется уже известная команда `vw`, в которую просто добавляются специальные параметры\n",
    "\n",
    "* `--span_server` - указываем адрес, где находится менеджер (spanning_tree). В нашем случае это localhost. В реальной жизни там мог бы быть IP адрес другой машины\n",
    "* `--unique_id` - так как один spanning_tree может обрабатывать сразу много различных процессов обучения, то необходимо их как-то разграничить. Для этого используется unique_id - это число, которое должно быть одинаковым для всех ваших рабочих, чтобы их не перепутали с другими. Например ваш коллега также обучает VW но для другой задачи - он может подключить свои VW к этому же spanning_tree указав для них unique_id = 0. В таком случае вам, чтобы подключиться, нужно запускать свои рабочие например с unique_id = 5, чтобы они не смешались с рабочими вашего коллеги.\n",
    "* `--total` - число рабочих, которое вы планируете подключить в текущей сессии обучения\n",
    "* `--node` - идентификатор текущего рабочего. Нумерация начинается с нуля, поэтому если вы хотите запустить 3 рабочих, то им нужно выдать значения для `--node` 0, 1 и 2.\n",
    "* `-d` - данные для обработки для текущего рабочего\n",
    "\n",
    "Все остальные параметры обучения должны быть одинаковыми для всех рабочих.\n",
    "\n",
    "Чтобы сохранить коэффициенты полученной модели, необходимо для какого-то одного рабочего указать через `-f` или `--final_regressor` файл, куда записать результат. Точно также, как мы это делали в предыдущей лабораторной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим двух рабочих. Первого запустим также в фоне, а вот второй запустим прямо в ноутбуке и будем следить за процессом обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg --out OUT --err ERR\n",
    "vw --span_server localhost --total 2 --node 0 --unique_id 1 -d airbnb-train-part1.vw --learning_rate 10.0 --bit_precision 22 --passes 20 --cache_file vw.cache1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = result.vw.bin\n",
      "Num weight bits = 22\n",
      "learning rate = 10\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = vw.cache2\n",
      "Reading datafile = airbnb-train-part2.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "2500.000000 2500.000000            1            1.0  50.0000   0.0000      139\n",
      "1627.909149 755.818298            2            2.0  75.0000  47.5079      178\n",
      "2737.117977 3846.326805            4            4.0 100.0000  13.5438       36\n",
      "2509.605871 2282.093765            8            8.0  90.0000 115.6549      172\n",
      "3019.351312 3529.096753           16           16.0 125.0000  42.2387      131\n",
      "24120.006490 45220.661667           32           32.0  18.0000  12.4142       57\n",
      "55243.550235 86367.093980           64           64.0  84.0000 346.3909      187\n",
      "39819.820698 24396.091162          128          128.0  50.0000   0.0000       52\n",
      "31989.516599 24159.212499          256          256.0  40.0000  54.2828      171\n",
      "23348.218488 14706.920377          512          512.0  65.0000  50.5647       45\n",
      "23087.302102 22826.385715         1024         1024.0 136.0000  35.8223       49\n",
      "21774.631564 20461.961027         2048         2048.0  62.0000  37.6488       34\n",
      "20477.053406 19179.475249         4096         4096.0  90.0000 216.5686      171\n",
      "18576.293788 16675.534170         8192         8192.0  31.0000  98.1610      203\n",
      "17672.355118 16768.416447        16384        16384.0 350.0000 305.8569      179\n",
      "16836.942513 16001.529908        32768        32768.0 220.0000 191.0289      168\n",
      "connecting to 127.0.0.1 = localhost:26543\n",
      "wrote unique_id=1\n",
      "wrote total=2\n",
      "wrote node=1\n",
      "read ok=1\n",
      "read kid_count=1\n",
      "read parent_ip=255.255.255.255\n",
      "read parent_port=65535\n",
      "16134.450825 16134.450825        65536        65536.0  32.0000  40.5524      190 h\n",
      "14956.957780 13779.626457       131072       131072.0 109.0000 143.8977      167 h\n",
      "14055.109279 13153.322708       262144       262144.0 120.0000 164.9583      172 h\n",
      "13130.106240 12205.103202       524288       524288.0  99.0000 187.8642      175 h\n",
      "12501.669806 11873.222581      1048576      1048576.0  88.0000  89.0964      184 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 118630\n",
      "passes used = 20\n",
      "weighted example sum = 2372600.000000\n",
      "weighted label sum = 325923904.000000\n",
      "average loss = 23422.878906 h\n",
      "best constant = 137.369934\n",
      "total feature number = 312653312\n",
      "CPU times: user 120 ms, sys: 26 ms, total: 146 ms\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! vw --span_server localhost --total 2 --node 1 --unique_id 1 -d airbnb-train-part2.vw -f result.vw.bin --learning_rate 10.0 --bit_precision 22 --passes 20 --cache_file vw.cache2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def read_target_from_vw(vw_object):\n",
    "    return float(vw_object.split(' ')[0])\n",
    "\n",
    "def calc_r2(predictions_path, answers_path):\n",
    "    with open(predictions_path, 'r') as f:\n",
    "        y_pred = np.array([float(value) for value in f.readlines()])\n",
    "        \n",
    "    with open(answers_path, 'r') as f:\n",
    "        y_expected = np.array([read_target_from_vw(value) for value in f.readlines()])\n",
    "        \n",
    "    return r2_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = predictions.txt\n",
      "Num weight bits = 22\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "2500.000000 2500.000000            1            1.0  50.0000   0.0000      193\n",
      "1361.884918 223.769836            2            2.0  77.0000  91.9589      168\n",
      "13769.519379 26177.153839            4            4.0 320.0000  92.7128      171\n",
      "8775.625010 3781.730640            8            8.0  75.0000  61.4763      197\n",
      "6514.805589 4253.986169           16           16.0  50.0000  71.4327       59\n",
      "7108.112527 7701.419464           32           32.0  39.0000  48.9865      185\n",
      "17976.902963 28845.693399           64           64.0 249.0000 105.9728      152\n",
      "14032.351608 10087.800252          128          128.0 201.0000 146.9716       37\n",
      "13260.489458 12488.627308          256          256.0  32.0000 121.3769      171\n",
      "10016.787432 6773.085406          512          512.0  98.0000  58.9342      172\n",
      "10348.914239 10681.041046         1024         1024.0 140.0000 103.3946      172\n",
      "10416.921464 10484.928690         2048         2048.0  69.0000 146.3856      193\n",
      "10763.193181 11109.464897         4096         4096.0 149.0000 139.9479      179\n",
      "10459.234103 10155.275026         8192         8192.0 378.0000 437.0699      198\n",
      "11022.285411 11585.336720        16384        16384.0 600.0000 384.7236      187\n",
      "11011.670870 11001.056328        32768        32768.0 180.0000 180.5164       57\n",
      "\n",
      "finished run\n",
      "number of examples = 64899\n",
      "weighted example sum = 64899.000000\n",
      "weighted label sum = 8892274.000000\n",
      "average loss = 11226.899809\n",
      "best constant = 137.017120\n",
      "total feature number = 8547036\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor result.vw.bin --predictions predictions.txt airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4728293051772131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_r2(\"predictions.txt\", \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В текущем окружении сильно большой разницы в скорости обучения мы не заметим, потому как \n",
    "* данных на самом деле очень немного\n",
    "* мы все еще запускаем все на одной машине\n",
    "\n",
    "Однако можно видеть, что концептуально схема совершенно рабочая - только что мы распределенно рассчитали линейную модель и получили относительно неплохое качество.\n",
    "\n",
    "Более того можно видеть, что VW за счет своих оптимизаций (хеширование, tree allreduce и так далее) значительно обходит решение на Spark как по скорости расчета, так и по качеству получаемой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
