{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хеширование признаков\n",
    "\n",
    "Рассмотрим прием с хешированием и изучим инструменты, которые успешно его применяют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"airbnb-100k.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Hi everyone, Cosy bedroom in a modern apartmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.0</td>\n",
       "      <td>Very comfortable and calm apartment, 2 rooms i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>At a few minutes by walking from République, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Come stay here in my little nest. It's a very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Studio de 25 m2, idéalement situé au centre de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price                                        Description\n",
       "0   50.0  Hi everyone, Cosy bedroom in a modern apartmen...\n",
       "1  125.0  Very comfortable and calm apartment, 2 rooms i...\n",
       "2   59.0  At a few minutes by walking from République, O...\n",
       "3   50.0  Come stay here in my little nest. It's a very ...\n",
       "4   48.0  Studio de 25 m2, idéalement situé au centre de..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачу будем решать такую же - предсказываем цену апартаментов по текстовому описанию. \n",
    "\n",
    "### Vowpal Wabbit\n",
    "\n",
    "Vowpal Wabbit - продвинутый инструмент, оптимизированный для обучения линейных моделей на больших объемах данных. Он активно использует хеширование признаков для своей работы. \n",
    "\n",
    "Это инструмент командной строки, который доступен в виде команды `vw`.\n",
    "\n",
    "Полную информацию можно найти на <a href=\"https://vowpalwabbit.org/\">официальном сайте</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = \n",
      "num sources = 1\n",
      "driver:\n",
      "  --onethread           Disable parse thread\n",
      "VW options:\n",
      "  --ring_size arg (=256, ) size of example ring\n",
      "  --strict_parse           throw on malformed examples\n",
      "Update options:\n",
      "  -l [ --learning_rate ] arg Set learning rate\n",
      "  --power_t arg              t power value\n",
      "  --decay_learning_rate arg  Set Decay factor for learning_rate between passes\n",
      "  --initial_t arg            initial t value\n"
     ]
    }
   ],
   "source": [
    "! vw --help | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формат данных\n",
    "\n",
    "VW для обучения требует свой особенный формат хранения данных. Он выглядит следующим образом: \n",
    "\n",
    "```\n",
    "[Label] [Importance] [Tag]|Namespace Features |Namespace Features ... |Namespace Features\n",
    "```\n",
    "\n",
    "* Label - значение целевой переменной. Если не указывать, объект не будет использоваться в обучении\n",
    "* Importance - вес объекта. Если не указывать, равен 1\n",
    "* Tag - пометка объекта. Никак не влияет на процесс обучения, но добавляет семантики и \"читаемости\" данных для человека\n",
    "* Namespace - название области признаков. Используется, чтобы разные по сути признаки с одинаковым названием не пересекались\n",
    "* Features - признаки. Это или пара <название признака>:<значение признака> или просто <название признака>. В последнем случае будет считаться, что значение равно 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, попробуем закодировать несколько элементов из Iris в этом формате\n",
    "\n",
    "| Длина чашелистика | Ширина чашелистика | Длина лепестка | Ширина лепестка |  Вид ириса |\n",
    "|:-----------------:|:------------------:|:--------------:|:---------------:|:----------:|\n",
    "| 5.1               | 3.5                | 1.4            | 0.2             | setosa     |\n",
    "| 4.9               | 3.0                | 1.4            | 0.2             | setosa     |\n",
    "| 7.0               | 3.2                | 4.7            | 1.4             | versicolor |\n",
    "\n",
    "Будем считать setosa классом 1, а versicolor классом -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_1.example.vw\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_1.example.vw\n",
    "1 | sepal_length:5.1 sepal_width:3.5 petal_length:1.4 petal_width:0.2\n",
    "1 | sepal_length:4.9 sepal_width:3.0 petal_length:1.4 petal_width:0.2\n",
    "-1 | sepal_length:7.0 sepal_width:3.2 petal_length:4.7 petal_width:1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном наборе мы дополнительно можем сгруппировать признаки - признаки для чашелистика и признаки для лепестка. Это позволит логически их разделить, сэкономит место, а также позволит в дальнейшем оперировать этими группами.\n",
    "\n",
    "Запишем точно эти же данные, но с использованием именованных секций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_2.example.vw\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_2.example.vw\n",
    "1 |sepal length:5.1 width:3.5 |petal length:1.4 width:0.2\n",
    "1 |sepal length:4.9 width:3.0 |petal length:1.4 width:0.2\n",
    "-1 |sepal length:7.0 width:3.2 |petal length:4.7 width:1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобный формат записи данных позволяет очень удобно записывать категориальные признаки в формате One-Hot Encoding. При таком кодировании мы бы для признака, соответствующего конкретной категории, выставили бы значение 1, а всем остальным - 0.\n",
    "\n",
    "Например для признака с полом человека превратится в два признака\n",
    "\n",
    "| gender_man | gender_woman |\n",
    "|:----------:|:------------:|\n",
    "| 1          | 0            |\n",
    "\n",
    "Если же в VW не указывать явно значение признака, то оно будет в автоматическом режиме выставлено равным 1, чего мы и ожидаем при One-Hot кодировании.\n",
    "\n",
    "Попробуем для примера записать вот такие данные в этом формате\n",
    "\n",
    "| Класс |  Цвет фона | Включена ли темная тема | Размер шрифта | Межстрочный интервал |\n",
    "|:-----:|:----------:|:-----------------------:|:-------------:|:--------------------:|\n",
    "| 1     | White      | да                      | 12            | 1.5                  |\n",
    "| -1    | Black      | нет                     | 14            | 1.5                  |\n",
    "| 1     | White, Red | нет                     | 12            | 2                    |\n",
    "| -1    | Black, Red | да                      | 15            | 1.5                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing design.example.vw\n"
     ]
    }
   ],
   "source": [
    "%%writefile design.example.vw\n",
    "1 |color white |theme dark |font size:12.0 interval:1.5\n",
    "-1 |color black |theme normal |font size:14.0 interval:1.5\n",
    "1 |color white red |theme normal |font size: 12.0 interval:2.0\n",
    "-1 |color black red |theme dark |font size: 15.0 interval:1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что такой подход к кодированию также позволяет очень просто кодировать текстовые признаки в формате bag-of-words. При использовании bag-of-words мы для каждого слова добавляет отдельный бинарный признак, который равен 1, если слово есть в тексте.\n",
    "\n",
    "Таким образом, чтобы закодировать в формате vw какой-то текст через bag-of-words достаточно... Просто написать этот текст! Единственное, что необходимо сделать дополнительно - это очистить сам текст от лишних символов, таких как знаки препинания, удаления, кавычки и так далее. Очищенный текст - это и есть кодирование признаков в vw.\n",
    "\n",
    "Попробуем, например, закодировать вот такой набор данных.\n",
    "\n",
    "| Оценка |                             Заголовок                              |                                                                      Комментарий                                                                     |\n",
    "|:------:|:------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| 2      | To lazy to watch film                                              | My family and I normally do not watch local movies for the simple reason that they are poorly made                                                   |\n",
    "| 5      | Well-directed and fairly notorious piece of Italian nunsploitation | This file is a genuinely moving and intelligent movie with plenty of nudity and gore.You can't go wrong with it.5 out of 5.                         |\n",
    "| 3      | this was at one time the worst movie I had ever seen               | But since than time, I have seen many more movies that are worse (how is it possible??) Therefore, to be fair, I had to give this movie a 3 out of 5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reviews.vw\n"
     ]
    }
   ],
   "source": [
    "%%writefile reviews.vw\n",
    "2.0 |title to lazy to watch film |review my family and i normally do not watch local movies for the simple reason that they are poorly made\n",
    "5.0 |title well directed and fairly notorious piece of italian nunsploitation |review this file is a genuinely moving and intelligent movie with plenty of nudity and gore you can t go wrong with it 8 out of 10 \n",
    "3.0 |title this was at one time the worst movie i had ever seen |review but since than time  i have seen many more movies that are worse how is it possible  therefore to be fair  i had to give this movie a 3 out of 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 |title to lazy to watch film |review my family and i normally do not watch local movies for the simple reason that they are poorly made\n",
      "5.0 |title well directed and fairly notorious piece of italian nunsploitation |review this file is a genuinely moving and intelligent movie with plenty of nudity and gore you can t go wrong with it 8 out of 10 \n",
      "3.0 |title this was at one time the worst movie i had ever seen |review but since than time  i have seen many more movies that are worse how is it possible  therefore to be fair  i had to give this movie a 3 out of 5 \n"
     ]
    }
   ],
   "source": [
    "! cat reviews.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере именованные секции играют важную роль, так как одно и тоже слово может оказаться и в заголовке и в тексте комментария. Без секций мы бы считали это одним признаком. Секции позволяют нам разделять слова, которые использовались в заголовке от слов, которые использовались в описании.\n",
    "\n",
    "Итак, мы научились формировать данные для VW, самое время запустить его. Попробуем использовать наши примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = reviews_result.vw.bin\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = reviews.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "4.000000 4.000000            1            1.0   2.0000   0.0000       25\n",
      "13.653724 23.307447            2            2.0   5.0000   0.1722       36\n",
      "\n",
      "finished run\n",
      "number of examples = 3\n",
      "weighted example sum = 3.000000\n",
      "weighted label sum = 10.000000\n",
      "average loss = 10.574909\n",
      "best constant = 3.333333\n",
      "total feature number = 106\n"
     ]
    }
   ],
   "source": [
    "! vw reviews.vw --final_regressor reviews_result.vw.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На экране можно видеть отчет обучения, а в файл `reviews_result.vw.bin` записались веса модели. По-умолчанию используется линейная регрессия с MSE.\n",
    "\n",
    "Для того, чтобы получить предсказания нет отдельной команды. Это связано с особым форматом работы инструмента. Можно считать, что vw всегда запускается в режиме обучения, однако есть несколько флагов, которые умеют контролировать этот процесс.\n",
    "\n",
    "Схематично это можно изобразить на картинке\n",
    "\n",
    "<img src=\"img/vw.png\">\n",
    "\n",
    "Таким образом при каждом запуске VW получает входные данные, с которыми он сейчас будет работать. Далее он начинает обучение на этих данных. Если указан `--initial_regressor` то он возьмет указанные веса в качестве начальных - то есть попытается \"дообучить\" модель, которую мы указали. Параллельно с этим для каждого пройденного элемента он производит предсказание. Если указать параметр `--predictions`, то эти данные он отдельно запишет в файл. По окончанию обучения новые полученные веса он попробует сохранить в файл, указанный через `--final_regressor`. И также есть очень важный флаг `--testonly`, говорящий о том, что обновлять веса (то есть обучаться) в процессе не требуется.\n",
    "\n",
    "Подобная схема позволяет более гибко задавать режимы работы. Вот возможные сценарии работы, которые можно выставить этими ключами.\n",
    "\n",
    "* `--final_regressor` - просто обучаем модель на данных\n",
    "* `--testonly`, `--initial_regressor`, `--predictions` - просто делаем предсказания модели на данных\n",
    "* `--final_regressor`, `--initial_regressor` - дообучаем модель на новых данных\n",
    "\n",
    "И так далее. Попробуем сделать предсказание на нашем же примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = reviews_prediction.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = reviews.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.042279 0.042279            1            1.0   2.0000   1.7944       25\n",
      "2.310258 4.578236            2            2.0   5.0000   2.8603       36\n",
      "\n",
      "finished run\n",
      "number of examples = 3\n",
      "weighted example sum = 3.000000\n",
      "weighted label sum = 10.000000\n",
      "average loss = 1.583771\n",
      "best constant = 3.333333\n",
      "total feature number = 106\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor reviews_result.vw.bin --predictions reviews_prediction.txt reviews.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.794381\n",
      "2.860319\n",
      "2.638340\n"
     ]
    }
   ],
   "source": [
    "! cat reviews_prediction.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы научились базовым приемам для работы с VW. Попробуем теперь обучить модель для решения оригинальной задачи. \n",
    "\n",
    "Для начала необходимо привести данные в нужный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_vw(raw_text, target):\n",
    "    word_pattern = re.compile(r\"[a-zA-Z0-9_]+\")\n",
    "    words = []\n",
    "    for match in re.finditer(word_pattern, raw_text.lower()):\n",
    "        words.append(match.group(0))\n",
    "    \n",
    "    if not words: \n",
    "        return None\n",
    "    return \"{} |d {}\".format(float(target), \" \".join(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 |d hi everyone cosy bedroom in a modern apartment located in a central area paris 11th the apartment it s a 2 bedrooms one is mine apartment of 47m2 509 sq ft fully renovated warm atmosphere a living room with a equiped kitchen wifi i provide towels and sheets central area cosmopolite non touristic very close to the marais bastille and republic transports 2 metro 3 walk saint ambroise line 9 or richard lenoir line 5 2 city bike station best j\n"
     ]
    }
   ],
   "source": [
    "example = convert_to_vw(df['Description'][0], df['Price'][0])\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Price', \"Description\"], inplace=True)\n",
    "Y = df['Price']\n",
    "X = df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vw(X_data, Y_data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for x, y in zip(X_data, Y_data):\n",
    "            vw_object = convert_to_vw(x, y)\n",
    "            if not vw_object:\n",
    "                continue\n",
    "            f.write(vw_object + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vw(X_train, y_train, \"airbnb-train.vw\")\n",
    "write_vw(X_test, y_test, \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497.0 |d bright cozy and simple 2 bedroom apartment with balcony furnished rental on amager in quiet and green surroundings close to the dr city concerthall and university amager f lled park and with several bathing options both at island s brygge and amager beach park 10 15min walking distance from amagerbro and dr city metro st which has good transport options the apartment is 47kvm with furnished living room bedroom kitchen bathroom and toilet wifi stereo tube amplifier with vinyl collection and a b o television tube stove fridge and basic kitchenware half of the living room has been designed for use as a studio workshop drawing painting and there is a little storage in the bedroom the apartment is simple with good details quiet neighbors and no noise from cars suitable for a person or couple the apartment is located at amager close to restaden and islands brygge the new dr building denmark s radio and television station with its large concert hall is 7 mi\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb-train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0 |d this holiday apartment in malaga with wifi is ideal for those who want to live in a quiet area close to the beach and malaga city center the accommodation offers a modern and stylish living room with dining table sofa armchair and a flat screen tv this holiday apartment in malaga with wifi is ideal for those who want to live in a quiet area close to the beach and malaga city center the accommodation offers a modern and stylish living room with dining table sofa armchair and a flat screen tv there is access to the private terrace a large fully equipped kitchen a bathroom with bath one bedroom with fitted wardrobes and double or single and another bedroom with fitted wardrobes double bed and en suite bathroom with shower we offer parking in the same building for 15 per day you can use the communal swimming pool from may to october optional services not included in the price garage price 15 per day minimum 60 cot crib price 5 per day minimum 20\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65969\n"
     ]
    }
   ],
   "source": [
    "! cat airbnb-train.vw | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32482\n"
     ]
    }
   ],
   "source": [
    "! cat airbnb-test.vw | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = airbnb-lin-model-1.vw.bin\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-train.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "247009.000000 247009.000000            1            1.0 497.0000   0.0000      167\n",
      "124369.634766 1730.269531            2            2.0  42.0000   0.4035      185\n",
      "73513.864502 22658.094238            4            4.0 198.0000   0.2531        9\n",
      "67610.261047 61706.657593            8            8.0  49.0000   3.8943       47\n",
      "48401.856529 29193.452011           16           16.0  45.0000  13.4168      152\n",
      "33535.183784 18668.511038           32           32.0  30.0000  32.4405      183\n",
      "34466.191570 35397.199355           64           64.0  98.0000  43.0964      169\n",
      "22650.206457 10834.221345          128          128.0 119.0000  63.0574      176\n",
      "27579.568350 32508.930243          256          256.0 110.0000  77.0405      180\n",
      "25201.073051 22822.577753          512          512.0 250.0000 112.6686      170\n",
      "22831.894726 20462.716401         1024         1024.0  42.0000  97.2840      153\n",
      "23969.061508 25106.228289         2048         2048.0  29.0000  34.4555       37\n",
      "23634.104599 23299.147691         4096         4096.0 130.0000 186.4597      183\n",
      "24099.178130 24564.251660         8192         8192.0  40.0000 100.9860      148\n",
      "22652.182939 21205.187748        16384        16384.0 575.0000 155.5900      179\n",
      "22595.999894 22539.816848        32768        32768.0  26.0000  22.6811       27\n",
      "21931.228036 21266.456178        65536        65536.0  32.0000 139.4530      176\n",
      "\n",
      "finished run\n",
      "number of examples = 65969\n",
      "weighted example sum = 65969.000000\n",
      "weighted label sum = 8964861.000000\n",
      "average loss = 21926.672941\n",
      "best constant = 135.895050\n",
      "total feature number = 8691727\n",
      "CPU times: user 7.42 ms, sys: 12.1 ms, total: 19.5 ms\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! vw --final_regressor airbnb-lin-model-1.vw.bin airbnb-train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = airbnb-1-predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "12414.840820 12414.840820            1            1.0  67.0000 178.4219      176\n",
      "6385.283173 355.725525            2            2.0 149.0000 167.8607      178\n",
      "5797.542808 5209.802442            4            4.0  50.0000 152.0667      177\n",
      "11372.974285 16948.405762            8            8.0  55.0000  94.2239      140\n",
      "11254.900320 11136.826355           16           16.0 349.0000 228.8699      183\n",
      "7937.500353 4620.100387           32           32.0  73.0000 115.0770      168\n",
      "6498.084106 5058.667860           64           64.0  52.0000  99.1681       99\n",
      "14933.415227 23368.746347          128          128.0  49.0000 144.8301      167\n",
      "14273.016348 13612.617468          256          256.0  80.0000  71.1772       76\n",
      "16832.732596 19392.448845          512          512.0 135.0000 162.7533      190\n",
      "20726.525218 24620.317839         1024         1024.0  55.0000  21.7267       41\n",
      "20648.483469 20570.441721         2048         2048.0  89.0000  41.1130       83\n",
      "21607.880514 22567.277559         4096         4096.0 190.0000 156.3036      172\n",
      "21309.478193 21011.075872         8192         8192.0  80.0000  38.7337       27\n",
      "21348.042119 21386.606045        16384        16384.0 129.0000 126.8273      161\n",
      "\n",
      "finished run\n",
      "number of examples = 32482\n",
      "weighted example sum = 32482.000000\n",
      "weighted label sum = 4456861.000000\n",
      "average loss = 21400.051623\n",
      "best constant = 137.210175\n",
      "total feature number = 4305298\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor airbnb-lin-model-1.vw.bin --predictions airbnb-1-predictions.txt airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178.421906\n",
      "167.860687\n",
      "131.414352\n",
      "152.066666\n",
      "24.521982\n",
      "172.426620\n",
      "43.975327\n",
      "94.223877\n",
      "86.247917\n",
      "138.389420\n"
     ]
    }
   ],
   "source": [
    "! head airbnb-1-predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('airbnb-1-predictions.txt', 'r') as f:\n",
    "    y_pred = np.array([float(value) for value in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_target_from_vw(vw_object):\n",
    "    return float(vw_object.split(' ')[0])\n",
    "\n",
    "with open('airbnb-test.vw', 'r') as f:\n",
    "    y_expected = np.array([read_target_from_vw(value) for value in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.421906, 167.860687, 131.414352, ..., 129.718094,  50.806786,\n",
       "       118.676826])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67., 149., 130., ...,  45.,  45., 110.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.042711300260121154"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, качество пока не впечатляет. Это связано с тем, что начальные параметры VW достаточно слабые. Однако у VW их достаточно большое количество, что позволяет весьма гибко менять обучаемую модель. Все параметры можно посмотреть, вызвав `vw --help`. Мы рассмотрим несколько важных из них.\n",
    "\n",
    "* Регуляризация - можно указывать и l1 и l2 через `--l1`, `--l2`\n",
    "* Размер хеша - можно указать размер признакового пространства после хеширования. Указывается в битах, то есть, указав этот параметр 10, у модели будет 2^10 признаков. Чем больше, чем меньше коллизий и лучше качество. Однако увеличивается потребление памяти и время на расчет. Параметр `--bit_precision`\n",
    "* Количество эпох - можно указать, сколько раз алгоритму необходимо пройтись по данных в процессе обучения. Для использования также необходимо указать кеш-файл - файл, где будут сохраняться промежуточные результаты. Параметры `--passes` и `--cache_file` соответственно.\n",
    "* Скорость обучения (learning rate) - можно указать скорость для градиентного спуска. Параметр `--learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'vw.cache': No such file or directory\n",
      "final_regressor = airbnb-lin-model-2.vw.bin\n",
      "Num weight bits = 22\n",
      "learning rate = 10\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = vw.cache\n",
      "Reading datafile = airbnb-train.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "247009.000000 247009.000000            1            1.0 497.0000   0.0000      167\n",
      "124107.208374 1205.416748            2            2.0  42.0000   7.2809      185\n",
      "71598.113556 19089.018738            4            4.0 198.0000   4.3248        9\n",
      "53879.962028 36161.810500            8            8.0  49.0000  49.0281       47\n",
      "35996.759609 18113.557190           16           16.0 160.0000  55.5732       39\n",
      "22678.413670 9360.067731           32           32.0  35.0000 168.3842      177\n",
      "25525.760121 28373.106572           64           64.0  70.0000 104.9430      175\n",
      "14651.196136 3776.632151          128          128.0  99.0000 119.4705      173\n",
      "21146.945070 27642.694004          256          256.0  80.0000  12.5028       42\n",
      "19380.930454 17614.915838          512          512.0  44.0000  33.5358       36\n",
      "19642.909594 19904.888734         1024         1024.0  28.0000  33.0253       31\n",
      "19745.319444 19847.729294         2048         2048.0  57.0000 129.7083      181\n",
      "19325.440909 18905.562374         4096         4096.0 150.0000 120.3732      168\n",
      "19160.736406 18996.031903         8192         8192.0  45.0000  60.4046       60\n",
      "17347.501704 15534.267003        16384        16384.0  90.0000  34.0568       43\n",
      "16547.105635 15746.709565        32768        32768.0  50.0000  86.0013       66\n",
      "14916.505299 14916.505299        65536        65536.0 350.0000 211.1074      183 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 59373\n",
      "passes used = 2\n",
      "weighted example sum = 118746.000000\n",
      "weighted label sum = 16127814.000000\n",
      "average loss = 13035.332031 h\n",
      "best constant = 135.817749\n",
      "total feature number = 15623330\n",
      "CPU times: user 22.8 ms, sys: 19 ms, total: 41.8 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! (rm vw.cache || exit 0)\n",
    "! vw --final_regressor airbnb-lin-model-2.vw.bin airbnb-train.vw --learning_rate 10.0 --bit_precision 22 --passes 2 --cache_file vw.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_r2(predictions_path, answers_path):\n",
    "    with open(predictions_path, 'r') as f:\n",
    "        y_pred = np.array([float(value) for value in f.readlines()])\n",
    "        \n",
    "    with open(answers_path, 'r') as f:\n",
    "        y_expected = np.array([read_target_from_vw(value) for value in f.readlines()])\n",
    "        \n",
    "    return r2_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = airbnb-2-predictions.txt\n",
      "Num weight bits = 22\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1263.947876 1263.947876            1            1.0  67.0000  31.4480      176\n",
      "2847.513000 4431.078125            2            2.0 149.0000 215.5663      178\n",
      "1731.842186 616.171371            4            4.0  50.0000  80.1333      177\n",
      "4962.735058 8193.627930            8            8.0  55.0000   8.1013      140\n",
      "16185.806010 27408.876963           16           16.0 349.0000 313.6222      183\n",
      "9241.604786 2297.403561           32           32.0  73.0000   5.6624      168\n",
      "6536.176171 3830.747556           64           64.0  52.0000 130.6690       99\n",
      "12581.899921 18627.623671          128          128.0  49.0000  63.5432      167\n",
      "10096.082984 7610.266046          256          256.0  80.0000  77.5728       76\n",
      "10599.835777 11103.588569          512          512.0 135.0000 169.1063      190\n",
      "13028.528930 15457.222083         1024         1024.0  55.0000  54.3300       41\n",
      "12699.725809 12370.922688         2048         2048.0  89.0000  73.0682       83\n",
      "12922.811525 13145.897241         4096         4096.0 190.0000 186.7068      172\n",
      "12770.322447 12617.833370         8192         8192.0  80.0000  95.5469       27\n",
      "12923.961121 13077.599796        16384        16384.0 129.0000 130.9826      161\n",
      "\n",
      "finished run\n",
      "number of examples = 32482\n",
      "weighted example sum = 32482.000000\n",
      "weighted label sum = 4456861.000000\n",
      "average loss = 13004.632707\n",
      "best constant = 137.210175\n",
      "total feature number = 4305298\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor airbnb-lin-model-2.vw.bin --predictions airbnb-2-predictions.txt airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36635304933605783"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_r2(\"airbnb-2-predictions.txt\", \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так гораздо лучше! \n",
    "\n",
    "Если сравнивать с моделью PCA + линейная модель и линейная модель на сырых данных, которые мы рассматривали в предыдущий раз, результаты следующие\n",
    "\n",
    "* Качество выросло с ~0.2 до ~0.37, то есть почти в **2 раза**\n",
    "* Время обучения упало с 60 и 40 секунд до ~2 , то есть в **35** и  **20** раз соответственно\n",
    "\n",
    "Очень неплохой результат, но это не все возможности vw. Здесь есть возможность более агресивно использовать метод хеширования - хеширование позволяет нам обрабатывать потенциально любое количество признаков. Почему бы тогда не увеличивать это количество признаков?\n",
    "\n",
    "Один из способов - это использовать N-граммы, чтобы учитывать подряд идущие слова. Для этого используется параметр `--ngram`.\n",
    "\n",
    "Или можно комбинировать признаки сами с собой. Другими словами мы будем рассматривать в качестве признаков все возможные пары слов, которые есть в тексте. Например, предложение \"Good luck, Mike\" будет рассматриваться как [\"Good\", \"luck\", \"Mike\", \"Good Mike\", \"Good luck\", \"luck Mike\"]. Для комбинирования используется `--quadratic`.\n",
    "\n",
    "Стоит заметить, что изначальных признаков было примерно 100000, а значит новых признаков будет больше чем 100000^2 - огромное число, но хеширование позволяет с этим справится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = airbnb-lin-model-3.vw.bin\n",
      "Num weight bits = 22\n",
      "learning rate = 10\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = vw.cache\n",
      "Reading datafile = airbnb-train.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "247009.000000 247009.000000            1            1.0 497.0000   0.0000      496\n",
      "124232.595703 1456.191406            2            2.0  42.0000   3.8399      550\n",
      "71759.649948 19286.704193            4            4.0 198.0000   2.2944       22\n",
      "57916.267544 44072.885139            8            8.0  49.0000  32.8372      136\n",
      "39630.302162 21344.336780           16           16.0 160.0000  38.7350      112\n",
      "24352.077421 9073.852680           32           32.0  35.0000 156.6530      526\n",
      "26083.726308 27815.375196           64           64.0  70.0000  72.0418      520\n",
      "15007.524854 3931.323400          128          128.0  99.0000 122.5884      514\n",
      "21111.344860 27215.164865          256          256.0  80.0000  24.5486      121\n",
      "19738.458163 18365.571466          512          512.0  44.0000  40.3413      103\n",
      "20021.429289 20304.400414         1024         1024.0  28.0000  33.1528       88\n",
      "20271.517436 20521.605582         2048         2048.0  57.0000 124.3061      538\n",
      "19845.767929 19420.018422         4096         4096.0 150.0000 143.4295      499\n",
      "19674.229748 19502.691567         8192         8192.0  45.0000  71.3006      175\n",
      "17791.967873 15909.705997        16384        16384.0  90.0000  33.5223      124\n",
      "16889.693635 15987.419398        32768        32768.0  50.0000  65.7229      193\n",
      "15125.745395 15125.745395        65536        65536.0 350.0000 308.9103      544 h\n",
      "14169.422019 13213.229989       131072       131072.0 200.0000 197.9887      508 h\n",
      "13486.524414 12803.673705       262144       262144.0  34.0000  29.2197      490 h\n",
      "13023.102182 12559.679950       524288       524288.0 150.0000 151.6515      565 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 59373\n",
      "passes used = 10\n",
      "weighted example sum = 593730.000000\n",
      "weighted label sum = 80639070.000000\n",
      "average loss = 12590.924805 h\n",
      "best constant = 135.817749\n",
      "total feature number = 231382050\n",
      "CPU times: user 265 ms, sys: 106 ms, total: 371 ms\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! (rm vw.cache || exit 0)\n",
    "! vw --final_regressor airbnb-lin-model-3.vw.bin airbnb-train.vw --ngram 3 --learning_rate 10.0 --bit_precision 22 --passes 10 --cache_file vw.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = airbnb-3-predictions.txt\n",
      "Num weight bits = 22\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "22654.406250 22654.406250            1            1.0  67.0000 217.5138      523\n",
      "18226.703125 13799.000000            2            2.0 149.0000 266.4691      529\n",
      "11001.010742 3775.318359            4            4.0  50.0000 120.3091      526\n",
      "7682.814874 4364.619006            8            8.0  55.0000  81.8713      415\n",
      "21170.683981 34658.553087           16           16.0 349.0000 431.0936      544\n",
      "13052.136917 4933.589853           32           32.0  73.0000  73.5171      499\n",
      "10177.577317 7303.017717           64           64.0  52.0000 127.6307      292\n",
      "14834.248912 19490.920508          128          128.0  49.0000  88.0676      496\n",
      "11281.903441 7729.557971          256          256.0  80.0000  64.1476      223\n",
      "11520.771497 11759.639553          512          512.0 135.0000 177.3247      565\n",
      "12826.140564 14131.509631         1024         1024.0  55.0000  67.8439      118\n",
      "12372.033913 11917.927262         2048         2048.0  89.0000  84.7598      244\n",
      "12334.306249 12296.578586         4096         4096.0 190.0000 204.0412      511\n",
      "12312.869572 12291.432894         8192         8192.0  80.0000  99.5481       76\n",
      "12557.122824 12801.376076        16384        16384.0 129.0000 127.3880      478\n",
      "\n",
      "finished run\n",
      "number of examples = 32482\n",
      "weighted example sum = 32482.000000\n",
      "weighted label sum = 4456861.000000\n",
      "average loss = 12615.301724\n",
      "best constant = 137.210175\n",
      "total feature number = 12753506\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor airbnb-lin-model-3.vw.bin --predictions airbnb-3-predictions.txt airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3853230867503401"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_r2(\"airbnb-3-predictions.txt\", \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще попытка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = airbnb-lin-model-4.vw.bin\n",
      "Num weight bits = 22\n",
      "learning rate = 40\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = vw.cache\n",
      "Reading datafile = airbnb-train.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "247009.000000 247009.000000            1            1.0 497.0000   0.0000      332\n",
      "123935.066101 861.132202            2            2.0  42.0000  12.6549      368\n",
      "75334.963226 26734.860352            4            4.0 198.0000   7.3048       16\n",
      "52160.772472 28986.581718            8            8.0  49.0000  65.4534       92\n",
      "34334.568857 16508.365242           16           16.0 160.0000  84.6049       76\n",
      "22621.677547 10908.786236           32           32.0  35.0000 204.7233      352\n",
      "25825.555672 29029.433797           64           64.0  70.0000 121.3315      348\n",
      "14812.930986 3800.306301          128          128.0  99.0000 124.4195      344\n",
      "21348.794264 27884.657541          256          256.0  80.0000  10.0323       82\n",
      "19775.807382 18202.820500          512          512.0  44.0000  60.6321       70\n",
      "19817.167693 19858.528003         1024         1024.0  28.0000  46.1360       60\n",
      "19145.375496 18473.583300         2048         2048.0  57.0000 122.0298      360\n",
      "18430.569268 17715.763040         4096         4096.0 150.0000 149.5845      334\n",
      "17376.848436 16323.127605         8192         8192.0  45.0000  69.0927      118\n",
      "15384.553755 13392.259074        16384        16384.0  90.0000  67.0932       84\n",
      "14431.048964 13477.544173        32768        32768.0  50.0000  72.4020      130\n",
      "13183.417557 13183.417557        65536        65536.0 350.0000 326.6848      364 h\n",
      "12465.346763 11747.374591       131072       131072.0 200.0000 174.8472      340 h\n",
      "12159.342599 11853.359449       262144       262144.0  34.0000  29.7673      328 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 59373\n",
      "passes used = 5\n",
      "weighted example sum = 296865.000000\n",
      "weighted label sum = 40319535.000000\n",
      "average loss = 11704.049805 h\n",
      "best constant = 135.817749\n",
      "total feature number = 77522920\n",
      "CPU times: user 51.5 ms, sys: 29.2 ms, total: 80.7 ms\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! (rm vw.cache || exit 0)\n",
    "! vw --final_regressor airbnb-lin-model-4.vw.bin airbnb-train.vw --ngram 2 --learning_rate 40.0 --bit_precision 22 --passes 50 --cache_file vw.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = airbnb-4-predictions.txt\n",
      "Num weight bits = 22\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test.vw\n",
      "num sources = 1\n",
      "Enabled reductions: gd, scorer\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "447.284821 447.284821            1            1.0  67.0000  88.1491      350\n",
      "3415.171463 6383.058105            2            2.0 149.0000 228.8940      354\n",
      "1819.696119 224.220776            4            4.0  50.0000  61.1000      352\n",
      "3070.560905 4321.425690            8            8.0  55.0000  25.7257      278\n",
      "21306.618166 39542.675428           16           16.0 349.0000 362.9811      364\n",
      "12854.457433 4402.296700           32           32.0  73.0000  91.6448      334\n",
      "8183.423551 3512.389669           64           64.0  52.0000  83.8710      196\n",
      "13523.373159 18863.322766          128          128.0  49.0000  55.6453      332\n",
      "10410.541198 7297.709238          256          256.0  80.0000  52.0745      150\n",
      "10063.753123 9716.965048          512          512.0 135.0000 115.9304      378\n",
      "11767.497283 13471.241443         1024         1024.0  55.0000  68.4444       80\n",
      "11526.678253 11285.859222         2048         2048.0  89.0000 114.6867      164\n",
      "11309.109621 11091.540990         4096         4096.0 190.0000 160.5997      342\n",
      "11345.368154 11381.626686         8192         8192.0  80.0000 100.5247       52\n",
      "11489.853524 11634.338895        16384        16384.0 129.0000 105.1600      320\n",
      "\n",
      "finished run\n",
      "number of examples = 32482\n",
      "weighted example sum = 32482.000000\n",
      "weighted label sum = 4456861.000000\n",
      "average loss = 11512.736962\n",
      "best constant = 137.210175\n",
      "total feature number = 8545632\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor airbnb-lin-model-4.vw.bin --predictions airbnb-4-predictions.txt airbnb-test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4390452357106146"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_r2(\"airbnb-4-predictions.txt\", \"airbnb-test.vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, манипулируя многочисленными параметрами vw можно быстро обучать модели на огромных массивах данных с хорошим качеством!\n",
    "\n",
    "Стоит отметить, что хеширование - это не уникальная особенность vw. Инструменты для его использования есть в других инструментах, например в sklearn или Spark.\n",
    "\n",
    "Для примера попробуем обучить модель sklearn с использованием хеширования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(n_features=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hash = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<98584x1024 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7780851 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_hash, Y, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 675 ms, sys: 11.7 ms, total: 687 ms\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor = Ridge(solver='sparse_cg').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26486168788999587\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
