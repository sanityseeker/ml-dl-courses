{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1E8yBOi_1Wy"
   },
   "source": [
    "# Поэтапный процесс ввода модели в эксплуатацию\n",
    "\n",
    "Процесс ввода в эксплуатацию должен снижать риск внесения некорректных изменений в сервис.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knBnf-SeJt2U"
   },
   "source": [
    "\n",
    "Основная задача в данной работе познакомиться с практической частью процесса проверки кандидатов на ввод в эксплуатацию на различных этапах. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBn3kfTxJwxp"
   },
   "source": [
    "\n",
    "Процесс непрерывной интеграции также можно автоматизировать, чтобы исключить человеческий фактор при тестировании версий моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7igk5luJw1g"
   },
   "source": [
    "\n",
    "Все изменения также можно смотреть в [интерфейсе MLflow](/app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvFqmcDgY0Zd"
   },
   "source": [
    "#### 0. Подготовка данных экспериментов\n",
    "\n",
    "Импортируем необходимые модули и определеим переменные.\n",
    "\n",
    "Код аналогичен первой лабораторной работе, заполняем реестр экспериментов для дальнейшей работы с ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tibeYuDjYzV6",
    "outputId": "0a3777d1-9e32-4ce2-a50f-ef33bddcc4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.300000, l1_ratio=0.500000):\n",
      "  RMSE: 0.8016125328127461\n",
      "  MAE: 0.6212322644038427\n",
      "  R2: 0.16903193835933472\n",
      "Elasticnet model (alpha=0.300000, l1_ratio=0.300000):\n",
      "  RMSE: 0.7945548693034976\n",
      "  MAE: 0.619032025971276\n",
      "  R2: 0.18359976351847052\n",
      "Elasticnet model (alpha=0.800000, l1_ratio=0.500000):\n",
      "  RMSE: 0.8584720333502169\n",
      "  MAE: 0.647722377274032\n",
      "  R2: 0.04696766019378218\n",
      "Elasticnet model (alpha=0.450000, l1_ratio=0.300000):\n",
      "  RMSE: 0.8035837903346776\n",
      "  MAE: 0.6216927531522227\n",
      "  R2: 0.16494002099488503\n",
      "Elasticnet model (alpha=0.200000, l1_ratio=0.300000):\n",
      "  RMSE: 0.7882632241950331\n",
      "  MAE: 0.6164326257018996\n",
      "  R2: 0.19647782690680782\n",
      "Elasticnet model (alpha=0.900000, l1_ratio=0.900000):\n",
      "  RMSE: 0.8600968020367704\n",
      "  MAE: 0.6471596692693683\n",
      "  R2: 0.043356773945086746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/03 20:16:32 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: sk-learn-model-ci, version 1\n",
      "2022/05/03 20:16:32 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: sk-learn-model-ci, version 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1651598192062, current_stage='Production', description='', last_updated_timestamp=1651598192068, name='sk-learn-model-ci', run_id='3cfe8a90187b40ebb9cd0d2bd472eb60', run_link='', source='./artifacts/1/3cfe8a90187b40ebb9cd0d2bd472eb60/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "MLFLOW_SERVER_URL = 'http://127.0.0.1:5000/'\n",
    "experiment_name = 'experiment-for-ci'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "data = pd.read_csv(\"mlflow-example/wine-quality.csv\")\n",
    "\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "# отложенная выборка\n",
    "test_later_x, test_x = test_x[:10], test_x[10:]\n",
    "test_later_y, test_y = test_y[:10], test_y[10:]\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "\n",
    "# подключаемся к серверу\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URL)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# запуск в эксперименте\n",
    "\n",
    "for alpha, l1_ratio in ((0.3, 0.5), (0.3, 0.3), (0.8, 0.5), (0.45, 0.3), (0.2, 0.3), (0.9, 0.9)):\n",
    "    with mlflow.start_run():\n",
    "        # модель\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # метрики\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        rmse = np.sqrt(mean_squared_error(test_y, predicted_qualities))\n",
    "        mae = mean_absolute_error(test_y, predicted_qualities)\n",
    "        r2 = r2_score(test_y, predicted_qualities)\n",
    "\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # сохраняем значения эксперимента в системе\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(lr, \"model\")\n",
    "\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "reg_model_name = \"sk-learn-model-ci\"\n",
    "client.create_registered_model(reg_model_name)\n",
    "# staging model\n",
    "run_info = client.list_run_infos(experiment.experiment_id)[0]\n",
    "result = client.create_model_version(\n",
    "    name=reg_model_name,\n",
    "    source=f\"{run_info.artifact_uri}/mdel\",\n",
    "    run_id=run_info.run_id\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=reg_model_name,\n",
    "    version=result.version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "# prod model\n",
    "run_info = client.list_run_infos(experiment.experiment_id)[1]\n",
    "result = client.create_model_version(\n",
    "    name=reg_model_name,\n",
    "    source=f\"{run_info.artifact_uri}/model\",\n",
    "    run_id=run_info.run_id\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=reg_model_name,\n",
    "    version=result.version,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_registered_model(reg_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STYWFUe-V6S-"
   },
   "source": [
    "### 1. Обзор существущей архитектуры и процесса ввода модели в эксплуатацию\n",
    "\n",
    "В MLflow зарегистрировано несколько запусков эксперимента с различными показателями метрик.\n",
    "\n",
    "Список экспериментов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBwf1hbhWWVq",
    "outputId": "2751b6ae-b2d9-4fc7-ce1e-b93dd77aca35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RunInfo: artifact_uri='./artifacts/1/4256cd4470f340429feae5957dcb75ef/artifacts', end_time=1651598191970, experiment_id='1', lifecycle_stage='active', run_id='4256cd4470f340429feae5957dcb75ef', run_uuid='4256cd4470f340429feae5957dcb75ef', start_time=1651598191153, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/3cfe8a90187b40ebb9cd0d2bd472eb60/artifacts', end_time=1651598191146, experiment_id='1', lifecycle_stage='active', run_id='3cfe8a90187b40ebb9cd0d2bd472eb60', run_uuid='3cfe8a90187b40ebb9cd0d2bd472eb60', start_time=1651598190335, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/294ea95825c54c3788c4c648977999d7/artifacts', end_time=1651598190329, experiment_id='1', lifecycle_stage='active', run_id='294ea95825c54c3788c4c648977999d7', run_uuid='294ea95825c54c3788c4c648977999d7', start_time=1651598189486, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/810db23064cf46d8bfa880a65bf8fca4/artifacts', end_time=1651598189480, experiment_id='1', lifecycle_stage='active', run_id='810db23064cf46d8bfa880a65bf8fca4', run_uuid='810db23064cf46d8bfa880a65bf8fca4', start_time=1651598188666, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/474f6e7b16714570b906ffa37d2b4691/artifacts', end_time=1651598188660, experiment_id='1', lifecycle_stage='active', run_id='474f6e7b16714570b906ffa37d2b4691', run_uuid='474f6e7b16714570b906ffa37d2b4691', start_time=1651598187843, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/b90b63587bb145ed8a3c18735e0dec9b/artifacts', end_time=1651598187837, experiment_id='1', lifecycle_stage='active', run_id='b90b63587bb145ed8a3c18735e0dec9b', run_uuid='b90b63587bb145ed8a3c18735e0dec9b', start_time=1651598187030, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/9f40d4f59351421d961ae0f0abd268ed/artifacts', end_time=1651598173605, experiment_id='1', lifecycle_stage='active', run_id='9f40d4f59351421d961ae0f0abd268ed', run_uuid='9f40d4f59351421d961ae0f0abd268ed', start_time=1651598172799, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/14a8f52e558443c6b66a8d275fa5b4f4/artifacts', end_time=1651598172793, experiment_id='1', lifecycle_stage='active', run_id='14a8f52e558443c6b66a8d275fa5b4f4', run_uuid='14a8f52e558443c6b66a8d275fa5b4f4', start_time=1651598171986, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/084aaea77ca54d8290b69ca00c165be3/artifacts', end_time=1651598171980, experiment_id='1', lifecycle_stage='active', run_id='084aaea77ca54d8290b69ca00c165be3', run_uuid='084aaea77ca54d8290b69ca00c165be3', start_time=1651598171168, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/dfb7d8a558d34da1baa7a0593b9431e3/artifacts', end_time=1651598171162, experiment_id='1', lifecycle_stage='active', run_id='dfb7d8a558d34da1baa7a0593b9431e3', run_uuid='dfb7d8a558d34da1baa7a0593b9431e3', start_time=1651598170352, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/e555e88cbf7d44c7ba648dba4589fa62/artifacts', end_time=1651598170346, experiment_id='1', lifecycle_stage='active', run_id='e555e88cbf7d44c7ba648dba4589fa62', run_uuid='e555e88cbf7d44c7ba648dba4589fa62', start_time=1651598169534, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/39acd1fa52d741a089d508b3eec802dd/artifacts', end_time=1651598169528, experiment_id='1', lifecycle_stage='active', run_id='39acd1fa52d741a089d508b3eec802dd', run_uuid='39acd1fa52d741a089d508b3eec802dd', start_time=1651598168403, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/4f9f4ae4a71a4d7ca36e626f03fe103f/artifacts', end_time=1651533090828, experiment_id='1', lifecycle_stage='active', run_id='4f9f4ae4a71a4d7ca36e626f03fe103f', run_uuid='4f9f4ae4a71a4d7ca36e626f03fe103f', start_time=1651533090019, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/29a3f9bd49b7449a8ad8d53ed7219a60/artifacts', end_time=1651533090012, experiment_id='1', lifecycle_stage='active', run_id='29a3f9bd49b7449a8ad8d53ed7219a60', run_uuid='29a3f9bd49b7449a8ad8d53ed7219a60', start_time=1651533089206, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/bf87ce4590434d96b2c28efabae6f547/artifacts', end_time=1651533089200, experiment_id='1', lifecycle_stage='active', run_id='bf87ce4590434d96b2c28efabae6f547', run_uuid='bf87ce4590434d96b2c28efabae6f547', start_time=1651533088382, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/a5fdbc9639614789a861769f2d36f39f/artifacts', end_time=1651533088376, experiment_id='1', lifecycle_stage='active', run_id='a5fdbc9639614789a861769f2d36f39f', run_uuid='a5fdbc9639614789a861769f2d36f39f', start_time=1651533087568, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/67347a84ce1e464f9f38a0c970cd7865/artifacts', end_time=1651533087562, experiment_id='1', lifecycle_stage='active', run_id='67347a84ce1e464f9f38a0c970cd7865', run_uuid='67347a84ce1e464f9f38a0c970cd7865', start_time=1651533086714, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/c43fb7a40ed942e9b6bc88e90ce6c3b5/artifacts', end_time=1651533086708, experiment_id='1', lifecycle_stage='active', run_id='c43fb7a40ed942e9b6bc88e90ce6c3b5', run_uuid='c43fb7a40ed942e9b6bc88e90ce6c3b5', start_time=1651533085860, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/640b599cb6dc4f7c9a0b8d7305a9ad4c/artifacts', end_time=1651532824652, experiment_id='1', lifecycle_stage='active', run_id='640b599cb6dc4f7c9a0b8d7305a9ad4c', run_uuid='640b599cb6dc4f7c9a0b8d7305a9ad4c', start_time=1651532823837, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/7399c9e891d5456cab1e49021a552eac/artifacts', end_time=1651532823831, experiment_id='1', lifecycle_stage='active', run_id='7399c9e891d5456cab1e49021a552eac', run_uuid='7399c9e891d5456cab1e49021a552eac', start_time=1651532823010, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/08e2e798cb3045be9e9fda8a5dcd9e5f/artifacts', end_time=1651532823004, experiment_id='1', lifecycle_stage='active', run_id='08e2e798cb3045be9e9fda8a5dcd9e5f', run_uuid='08e2e798cb3045be9e9fda8a5dcd9e5f', start_time=1651532822154, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/cca9f8ae75954daea006520122d13cd5/artifacts', end_time=1651532822148, experiment_id='1', lifecycle_stage='active', run_id='cca9f8ae75954daea006520122d13cd5', run_uuid='cca9f8ae75954daea006520122d13cd5', start_time=1651532821343, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/08bcdf63b1aa41db9f087bdfc1c8a383/artifacts', end_time=1651532821336, experiment_id='1', lifecycle_stage='active', run_id='08bcdf63b1aa41db9f087bdfc1c8a383', run_uuid='08bcdf63b1aa41db9f087bdfc1c8a383', start_time=1651532820497, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/b2f7e3e56ee049af88e9642f2cf323db/artifacts', end_time=1651532820491, experiment_id='1', lifecycle_stage='active', run_id='b2f7e3e56ee049af88e9642f2cf323db', run_uuid='b2f7e3e56ee049af88e9642f2cf323db', start_time=1651532819690, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/62af14f352b34b13a10f1e807d0347bc/artifacts', end_time=1651532736925, experiment_id='1', lifecycle_stage='active', run_id='62af14f352b34b13a10f1e807d0347bc', run_uuid='62af14f352b34b13a10f1e807d0347bc', start_time=1651532736116, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/801b1b936c34407689d4e61b4a45bef3/artifacts', end_time=1651532736110, experiment_id='1', lifecycle_stage='active', run_id='801b1b936c34407689d4e61b4a45bef3', run_uuid='801b1b936c34407689d4e61b4a45bef3', start_time=1651532735305, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/909a4d99f2a84e6da7150a80051f3dc6/artifacts', end_time=1651532735299, experiment_id='1', lifecycle_stage='active', run_id='909a4d99f2a84e6da7150a80051f3dc6', run_uuid='909a4d99f2a84e6da7150a80051f3dc6', start_time=1651532734491, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/e71e290c9e9347b7a2f525bf89c5f085/artifacts', end_time=1651532734485, experiment_id='1', lifecycle_stage='active', run_id='e71e290c9e9347b7a2f525bf89c5f085', run_uuid='e71e290c9e9347b7a2f525bf89c5f085', start_time=1651532733679, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/3841db56c81141b8a3e6a1eb12bdbca6/artifacts', end_time=1651532733673, experiment_id='1', lifecycle_stage='active', run_id='3841db56c81141b8a3e6a1eb12bdbca6', run_uuid='3841db56c81141b8a3e6a1eb12bdbca6', start_time=1651532732867, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/0cd0c0de98c242a4b8b64304b64aad10/artifacts', end_time=1651532732861, experiment_id='1', lifecycle_stage='active', run_id='0cd0c0de98c242a4b8b64304b64aad10', run_uuid='0cd0c0de98c242a4b8b64304b64aad10', start_time=1651532731791, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/c925f37d870d4bbf82fa76276a5c83ce/artifacts', end_time=1651532717044, experiment_id='1', lifecycle_stage='active', run_id='c925f37d870d4bbf82fa76276a5c83ce', run_uuid='c925f37d870d4bbf82fa76276a5c83ce', start_time=1651532716236, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/ce7670bdb51c43728f0468c2d44d6a27/artifacts', end_time=1651532716228, experiment_id='1', lifecycle_stage='active', run_id='ce7670bdb51c43728f0468c2d44d6a27', run_uuid='ce7670bdb51c43728f0468c2d44d6a27', start_time=1651532715420, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/964bf626553443f1afc74d185dae889c/artifacts', end_time=1651532715414, experiment_id='1', lifecycle_stage='active', run_id='964bf626553443f1afc74d185dae889c', run_uuid='964bf626553443f1afc74d185dae889c', start_time=1651532714607, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/bca80ac1e0694601b20452f2aa57a292/artifacts', end_time=1651532714601, experiment_id='1', lifecycle_stage='active', run_id='bca80ac1e0694601b20452f2aa57a292', run_uuid='bca80ac1e0694601b20452f2aa57a292', start_time=1651532713798, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/8133c4993a1147cc8f9ea50a4bba5b21/artifacts', end_time=1651532713792, experiment_id='1', lifecycle_stage='active', run_id='8133c4993a1147cc8f9ea50a4bba5b21', run_uuid='8133c4993a1147cc8f9ea50a4bba5b21', start_time=1651532712985, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/e28f51f0392245c99cadad06d135def9/artifacts', end_time=1651532712978, experiment_id='1', lifecycle_stage='active', run_id='e28f51f0392245c99cadad06d135def9', run_uuid='e28f51f0392245c99cadad06d135def9', start_time=1651532712171, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/4e52e9a06f044190a720ddca22e8481b/artifacts', end_time=1651532545738, experiment_id='1', lifecycle_stage='active', run_id='4e52e9a06f044190a720ddca22e8481b', run_uuid='4e52e9a06f044190a720ddca22e8481b', start_time=1651532544929, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/fbc1d5cf659a4ce5b2171713029a139a/artifacts', end_time=1651532544736, experiment_id='1', lifecycle_stage='active', run_id='fbc1d5cf659a4ce5b2171713029a139a', run_uuid='fbc1d5cf659a4ce5b2171713029a139a', start_time=1651532543932, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/8f097a1ac5904acd89cc872388aa89df/artifacts', end_time=1651532543926, experiment_id='1', lifecycle_stage='active', run_id='8f097a1ac5904acd89cc872388aa89df', run_uuid='8f097a1ac5904acd89cc872388aa89df', start_time=1651532543108, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/ebea6bac2cdc4bc2a9649ba91ac321ad/artifacts', end_time=1651532543100, experiment_id='1', lifecycle_stage='active', run_id='ebea6bac2cdc4bc2a9649ba91ac321ad', run_uuid='ebea6bac2cdc4bc2a9649ba91ac321ad', start_time=1651532542115, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/e5f6d1062d2042fcaa7a57f2f681a4ba/artifacts', end_time=1651532542108, experiment_id='1', lifecycle_stage='active', run_id='e5f6d1062d2042fcaa7a57f2f681a4ba', run_uuid='e5f6d1062d2042fcaa7a57f2f681a4ba', start_time=1651532541240, status='FINISHED', user_id='sanityseeker'>,\n",
       " <RunInfo: artifact_uri='./artifacts/1/33d437aba3b847eda2b5873b635572d7/artifacts', end_time=1651532541233, experiment_id='1', lifecycle_stage='active', run_id='33d437aba3b847eda2b5873b635572d7', run_uuid='33d437aba3b847eda2b5873b635572d7', start_time=1651532539946, status='FINISHED', user_id='sanityseeker'>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "client.list_run_infos(experiment.experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTguySIMV6sa"
   },
   "source": [
    "Одна из моделей зарегистрирована и введена в эксплуатацию.\n",
    "\n",
    "Текущая модель выложенная в  эксплуатационную среду (переведенная в `Production`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdMKPhHxWb1g",
    "outputId": "489c5fc0-b0b3-473a-98d2-7962ec13d8e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1651598192062, current_stage='Production', description='', last_updated_timestamp=1651598192068, name='sk-learn-model-ci', run_id='3cfe8a90187b40ebb9cd0d2bd472eb60', run_link='', source='./artifacts/1/3cfe8a90187b40ebb9cd0d2bd472eb60/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_prod = [v for v in client.search_model_versions(f\"name='{reg_model_name}'\") if v.current_stage == 'Production'][-1]\n",
    "current_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUu1npqIV62e"
   },
   "source": [
    "Также есть новая версия этой модели, выложенная в тестовую среду (переведенная в `Staging`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyXjo_5aWfxC",
    "outputId": "74018074-4258-4a02-96ad-1c323c2b1a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1651598192027, current_stage='Staging', description='', last_updated_timestamp=1651598192034, name='sk-learn-model-ci', run_id='4256cd4470f340429feae5957dcb75ef', run_link='', source='./artifacts/1/4256cd4470f340429feae5957dcb75ef/artifacts/mdel', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_staging = [v for v in client.search_model_versions(f\"name='{reg_model_name}'\") if v.current_stage == 'Staging'][-1]\n",
    "current_staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95pqRRd9KXSd"
   },
   "source": [
    "Задачей разработки в данном случае является обновление модели, не ухудшая метрик. Разберемся с этим детальнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEYadNDrV7C6"
   },
   "source": [
    "### 2. Процесс верификации новой версии и ввода в эксплуатацию\n",
    "\n",
    "Прежде чем переводить текущую модель кандидата на ввод в эксплуатацию из тестовой среды в эксплуатационную, следует протестировать корректность модели.\n",
    "\n",
    "Тестирование должно быть всесторонним и покрывать основные моменты эксплуатации модели.\n",
    "\n",
    "Например, запустим веб-сервер с тестируемой моделью и попробуем отправить тестовые запросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btdw6QVUJUEy",
    "outputId": "581f48ce-fa60-4726-dcb2-c62f146a32e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/bin/mlflow\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/mlflow/models/cli.py\", line 65, in serve\n",
      "    return _get_flavor_backend(\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/mlflow/models/cli.py\", line 204, in _get_flavor_backend\n",
      "    local_path = _download_artifact_from_uri(\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/mlflow/tracking/artifact_utils.py\", line 95, in _download_artifact_from_uri\n",
      "    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 74, in download_artifacts\n",
      "    return super().download_artifacts(artifact_path, dst_path)\n",
      "  File \"/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repo.py\", line 265, in download_artifacts\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: The following failures occurred while downloading one or more artifacts from ./artifacts/1/4f9f4ae4a71a4d7ca36e626f03fe103f/artifacts/mdel: {'MLmodel': \"FileNotFoundError(2, 'No such file or directory')\"}\n"
     ]
    }
   ],
   "source": [
    "! MLFLOW_TRACKING_URI=http://0.0.0.0:5000 mlflow models serve -m \"models:/sk-learn-model-ci/Staging\" -p 5005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWC-dAxiV7Pr"
   },
   "source": [
    "Видно, что эта версия модели некорректна и ее не следует переводить в эксплуатацию, так как в этом случае сервер будет неработоспособен.\n",
    "\n",
    "Обычно процесс верификации происходит с помощью систем непрерывной интеграции (например, Jenkins, TravisCI, CircleCI).\n",
    "\n",
    "Эти системы как правило используют скрипты для принятия решений аналогичные рассмотренным далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyxBSWKYWzH2"
   },
   "source": [
    "### 3. Откат версии с тестовой среды и отметка модели\n",
    "\n",
    "В случае, если тестирование модели неуспешно, необходимо откатить версию модели назад на стабильную и отметить не прошедшую тест модель, чтобы предотвратить ее возможную выкладку в будущем.\n",
    "\n",
    "#### Откат версии на эксплуатационную в тестовой среде\n",
    "\n",
    "В эксплуатационной среде сейчас находится работоспособная версия. Выложим эту же версию в тестовую среду, так как нам необходима работоспособная версия для последующего выбора кандидатов на ввод в эксплуатацию.\n",
    "\n",
    "Выкладка стабильной версии с эксплуатационной среды (`Production`) в тестовую (`Staging`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdZdCpc6XDYq",
    "outputId": "af3d372e-a096-413d-a654-ea894e462b31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/03 02:13:01 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: sk-learn-model-ci, version 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1651533181201, current_stage='Staging', description='', last_updated_timestamp=1651533181210, name='sk-learn-model-ci', run_id='29a3f9bd49b7449a8ad8d53ed7219a60', run_link='', source='./artifacts/1/29a3f9bd49b7449a8ad8d53ed7219a60/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание новой версии для тестовой среды из текущей эксплуатационной среды\n",
    "result = client.create_model_version(\n",
    "    name=current_prod.name,\n",
    "    source=current_prod.source,\n",
    "    run_id=current_prod.run_id\n",
    ")\n",
    "# Выкладка созданной версии в тестовую среду\n",
    "client.transition_model_version_stage(\n",
    "    name=current_prod.name,\n",
    "    version=result.version,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c33VGeDrXGWy"
   },
   "source": [
    "Такая операция также приводит тестовую среду к состоянию эксплуатационной, что позволяет проводить тестирование приближенное к эксплуатационной среде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDPulbzmXJTk"
   },
   "source": [
    "#### Отметка забракованной версии\n",
    "\n",
    "В данном случае, ошибка была при регистрации модели - некорректно указан путь к файлу модели. \n",
    "\n",
    "Путь можно обновить на корректный:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5M9X62JXLqN",
    "outputId": "d118c1c9-74a8-4f79-d1c6-67c85d2b93db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/03 20:27:38 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: sk-learn-model-ci, version 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1651598858504, current_stage='Staging', description='', last_updated_timestamp=1651598858524, name='sk-learn-model-ci', run_id='3cfe8a90187b40ebb9cd0d2bd472eb60', run_link='', source='./artifacts/1/4256cd4470f340429feae5957dcb75ef/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_staging = client.create_model_version(\n",
    "    name=current_prod.name,\n",
    "    source=current_staging.source.replace('mdel', 'model'), # баг был тут\n",
    "    run_id=current_prod.run_id\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=current_prod.name,\n",
    "    version=new_staging.version,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58aC0wOkJUFJ"
   },
   "source": [
    "Проверим, что теперь модель работает на тестовом сервере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ptb1luGPJUFO",
    "outputId": "5aa81dae-f3d9-4fe0-ae8e-febdcc7dbfbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py:2322: FutureWarning: `--no-conda` is deprecated and will be removed in a future MLflow release. Use `--env-manager=local` instead.\n",
      "  value = self.callback(ctx, self, value)\n",
      "2022/05/03 02:13:29 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/05/03 02:13:29 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 127.0.0.1:5005 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2022-05-03 02:13:29 +0300] [1020411] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-05-03 02:13:29 +0300] [1020411] [INFO] Listening at: http://127.0.0.1:5005 (1020411)\n",
      "[2022-05-03 02:13:29 +0300] [1020411] [INFO] Using worker: sync\n",
      "[2022-05-03 02:13:29 +0300] [1020413] [INFO] Booting worker with pid: 1020413\n"
     ]
    }
   ],
   "source": [
    "os.system('MLFLOW_TRACKING_URI=http://0.0.0.0:5000 mlflow models serve -m \"models:/sk-learn-model-ci/Staging\" -p 5005 --no-conda &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JDXX_7jJUFS",
    "outputId": "a5bb9cb8-5a40-4662-c989-6885e96f2040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [5.925164211632614, 5.964539037683882, 5.866425309090012, 5.983246407137424, 6.040856516155967, 5.476925826953726, 5.892059457193597, 5.826147448219497, 5.957386500329026, 5.733267307989582]\n",
      "      quality\n",
      "1876        6\n",
      "147         4\n",
      "3121        5\n",
      "4778        6\n",
      "4207        7\n",
      "70          6\n",
      "2870        7\n",
      "1969        7\n",
      "4289        6\n",
      "1239        5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f'http://127.0.0.1:5005/invocations'\n",
    "\n",
    "http_data = test_later_x[:10].to_json(orient='split')\n",
    "response = requests.post(url=url, headers={'Content-Type': 'application/json'}, data=http_data)\n",
    "\n",
    "print(f'Predictions: {response.text}')\n",
    "print(test_later_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lROBq_POXNn5"
   },
   "source": [
    "Чтобы предовратить в дальнейшем выкладку неработоспособной версии модели, можно отметить запуск подходящим тегом, например `staging: failed` и затем не использовать эту модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12oZtveMXQRU"
   },
   "outputs": [],
   "source": [
    "client.set_tag(current_staging.run_id, \"staging\", \"failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yS2F9HoZLkTx"
   },
   "source": [
    "Следующим образом можем сравнить метрики моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcUiwA01Ln1b"
   },
   "outputs": [],
   "source": [
    "new_staging_metrics = client.get_run(new_staging.run_id).data.metrics\n",
    "prod_metrics = client.get_run(current_prod.run_id).data.metrics\n",
    "\n",
    "# проверяем каждую метрику эксплуатационной модели\n",
    "if all(new_staging_metrics[k] > v for k, v in prod_metrics.items()):\n",
    "    # если новая модель лучше, то проставляем её как release candidate\n",
    "    # и указываем, с какой версией сравнивалась\n",
    "    client.set_tag(current_staging.run_id, \"staging\", \"rc\")\n",
    "    client.set_tag(current_staging.run_id, \"better_than\", current_prod.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOfS0GxOXRAV"
   },
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission():  # Генерация отчета выполнения задания\n",
    "    client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "    \n",
    "    runs = {}\n",
    "    models = [\n",
    "        {'name': m.name, \n",
    "         'versions': [\n",
    "             {'current_stage': v.current_stage, 'run_id': v.run_id, 'status': v.status} \n",
    "             for v in m.latest_versions if m.name == 'sk-learn-model-ci']} \n",
    "        for m in client.search_registered_models()\n",
    "    ]\n",
    "    for e in client.list_experiments():\n",
    "        if e.name == 'experiment-for-ci':\n",
    "            for run_info in client.list_run_infos(e.experiment_id):\n",
    "                run = mlflow.get_run(run_info.run_id)\n",
    "                runs[run_info.run_id] = {'run_id': run_info.run_id, 'tags': run.data.tags, 'params': run.data.params, 'metrics': run.data.metrics}\n",
    "    versions = [{'version': v.version, 'run_id': v.run_id} for v in client.search_model_versions(f\"name='{reg_model_name}'\")]\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump({'runs': runs, 'models': models, 'versions': versions}, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOfS0GxOXRAV"
   },
   "source": [
    "Процесс обновления модели состоит из двух этапов, первый - отбор кандидатов, которые лучше по общим метрикам, чем текущая модель в эксплуатации, второй - верификация модели на тестовом контуре также в сравнении с текущей эксплуатацией. Второй этап валидирует качество сервиса в целом, в то время как первый концентрируется именно на экспериментах с моделью.\n",
    "\n",
    "В качестве задания предлагается автоматизировать шаги обработки моделей.\n",
    "\n",
    "**1. Отметить следующими тегами все модели эксперимента (`run`), у которых метрика `rmse` лучше, чем у версии, которая сейчас используется в проде:**\n",
    "  `staging` = `rc` (release candidate)\n",
    "  \n",
    "  с помощью `client.set_tag(run.info.run_id, \"tag_key\", \"tag_value\")`\n",
    "\n",
    "  Если модель хуже, то следует проставить `staging` = `rejected`\n",
    "\n",
    "  Также следует проставить тег\n",
    "  `compared_with` = `%prod model version%` (возьмите версию из соответствующей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "def get_run_metrics(client: MlflowClient, run_id: str) -> dict:\n",
    "    return client.get_run(run_id).data.metrics\n",
    "\n",
    "def tag_release_candidates(client: MlflowClient, model_name: str, exp_name: str, metric_name: str) -> None:\n",
    "    curr_prod_model = [v for v in client.search_model_versions(f\"name='{model_name}'\") if v.current_stage == 'Production'][-1]\n",
    "    reference_metric_value = get_run_metrics(client, curr_prod_model.run_id)[metric_name]\n",
    "    \n",
    "    exp_id = client.get_experiment_by_name(exp_name).experiment_id\n",
    "    completed_runs = [run for run in client.search_runs(exp_id) if run.info.status == 'FINISHED']\n",
    "    \n",
    "    for run in completed_runs:\n",
    "        run_metric_value = run.data.metrics[metric_name]\n",
    "        \n",
    "        if run_metric_value <= reference_metric_value:\n",
    "            client.set_tag(run.info.run_id, 'staging', 'rc')\n",
    "        else:\n",
    "            client.set_tag(run.info.run_id, 'staging', 'rejected')\n",
    "        \n",
    "        client.set_tag(run.info.run_id, 'compared_with', curr_prod_model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_release_candidates(client, reg_model_name, experiment_name, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOfS0GxOXRAV"
   },
   "source": [
    "**2. Для всех моделей, прошедших первичный отбор, в порядке ухудшениия значения метрики `RMSE` из эксперимента, выложите модель на стейджинг и запустите тестовые запросы.**\n",
    "\n",
    "Посчитайте RMSE (напишите скрипт для запросов из `test_later_x`) ответов модели в тесте (`staging`) и в эксплуатации (`production`), если тестовые запросы дают показатели метрик хуже, чем у модели в эксплуатации, то модель следует пометить тегом `staging` = `failed`, затем перейти к следующей итерации - выложить на стейджинг следующего кандидата (`staging` = `rc`). Иначе следует выложить тестируемую модель в `Production` и обновить список кандидатов (тег `release candidates` из пункта 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_release_candidates(client: MlflowClient, exp_name: str, metric_name: str) -> list:\n",
    "    exp_id = client.get_experiment_by_name(exp_name).experiment_id\n",
    "    candidate_runs = [run for run in client.search_runs(exp_id) if run.data.tags['staging'] == 'rc']\n",
    "    \n",
    "    return sorted(candidate_runs, key=lambda run: run.data.metrics[metric_name], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcs = get_release_candidates(client, experiment_name, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOfS0GxOXRAV"
   },
   "source": [
    "3. Повторять до тех пор, пока существуют кандидаты, проходящие первичный отбор.\n",
    "\n",
    "Допишите скрипт, который итеративно выкладывает и верифицирует модели.\n",
    "\n",
    "После выполнения скрипта, запустите `generate_submission()`, чтобы сгенерировать файл `submission.json` для отправки задания на проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve_model(model_name: str, stage_name: str, port: int):\n",
    "    os.system(f'MLFLOW_TRACKING_URI=http://0.0.0.0:5000 mlflow models serve -m \"models:/{model_name}/{stage_name}\" -p {port} --no-conda &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_model_predictions(X_test: pd.DataFrame, port: int):\n",
    "    url = f'http://127.0.0.1:{port}/invocations'\n",
    "\n",
    "    http_data = X_test.to_json(orient='split')\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url=url, headers={'Content-Type': 'application/json'}, data=http_data)\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "    except Exception as e:\n",
    "        raise ConnectionError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py:2322: FutureWarning: `--no-conda` is deprecated and will be removed in a future MLflow release. Use `--env-manager=local` instead.\n",
      "  value = self.callback(ctx, self, value)\n",
      "2022/05/03 20:28:02 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/05/03 20:28:02 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 127.0.0.1:5005 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2022-05-03 20:28:02 +0300] [1063743] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-05-03 20:28:02 +0300] [1063743] [INFO] Listening at: http://127.0.0.1:5005 (1063743)\n",
      "[2022-05-03 20:28:02 +0300] [1063743] [INFO] Using worker: sync\n",
      "[2022-05-03 20:28:02 +0300] [1063745] [INFO] Booting worker with pid: 1063745\n"
     ]
    }
   ],
   "source": [
    "serve_model(reg_model_name, 'Staging', 5005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanityseeker/anaconda3/envs/ml-env/lib/python3.8/site-packages/click/core.py:2322: FutureWarning: `--no-conda` is deprecated and will be removed in a future MLflow release. Use `--env-manager=local` instead.\n",
      "  value = self.callback(ctx, self, value)\n",
      "2022/05/03 20:48:17 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/05/03 20:48:17 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b 127.0.0.1:5006 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2022-05-03 20:48:17 +0300] [1064658] [INFO] Starting gunicorn 20.1.0\n",
      "[2022-05-03 20:48:17 +0300] [1064658] [INFO] Listening at: http://127.0.0.1:5006 (1064658)\n",
      "[2022-05-03 20:48:17 +0300] [1064658] [INFO] Using worker: sync\n",
      "[2022-05-03 20:48:17 +0300] [1064660] [INFO] Booting worker with pid: 1064660\n"
     ]
    }
   ],
   "source": [
    "serve_model(reg_model_name, 'Production', 5006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def test_release_candidates(\n",
    "    client: MlflowClient,\n",
    "    model_name: str,\n",
    "    candidates: list,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.DataFrame,\n",
    "    error_func: callable,\n",
    "    staging_port: int = 5005,\n",
    "    prod_port: int = 5006,\n",
    ") -> bool:\n",
    "    prod_preds = get_model_predictions(X_test, prod_port)\n",
    "    prod_metric_res = error_func(y_test, prod_preds)\n",
    "    \n",
    "    for cand in tqdm(candidates):\n",
    "        model_version = client.create_model_version(\n",
    "        name=model_name,\n",
    "        source=f\"{cand.info.artifact_uri}/model\",\n",
    "        run_id=cand.info.run_id\n",
    "    )\n",
    "        \n",
    "        client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "        \n",
    "        stage_preds = get_model_predictions(X_test, staging_port)\n",
    "        stage_metric_res = error_func(y_test, stage_preds)\n",
    "        \n",
    "        if stage_metric_res < prod_metric_res:\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=model_version.version,\n",
    "                stage=\"Production\"\n",
    "            )\n",
    "            print('Successfully deployed to Production!')\n",
    "            return True  # return True if successful Staging deploy\n",
    "        else:\n",
    "            client.set_tag(cand.info.run_id, 'staging', 'rc')\n",
    "    \n",
    "    print('Nothing was deployed')\n",
    "    return False  # return False if all candidates are worse than Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ea84701f554e4590dd3392ccb99772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/03 21:41:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: sk-learn-model-ci, version 6\n"
     ]
    }
   ],
   "source": [
    "succeed = test_release_candidates(\n",
    "    client,\n",
    "    reg_model_name,\n",
    "    rcs,\n",
    "    test_later_x,\n",
    "    test_later_y,\n",
    "    error_func=lambda x, y: np.sqrt(mean_squared_error(x, y))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if succeed:\n",
    "    tag_release_candidates(client, reg_model_name, experiment_name, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итеративная выкладка лучших моделей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succeed = True\n",
    "\n",
    "while succeed:\n",
    "\n",
    "    tag_release_candidates(client, reg_model_name, experiment_name, 'rmse')\n",
    "    rcs = get_release_candidates(client, experiment_name, 'rmse')\n",
    "\n",
    "    succeed = test_release_candidates(\n",
    "        client,\n",
    "        reg_model_name,\n",
    "        rcs,\n",
    "        test_later_x,\n",
    "        test_later_y,\n",
    "        error_func=lambda x, y: np.sqrt(mean_squared_error(x, y))\n",
    "    )\n",
    "\n",
    "    if succeed:\n",
    "        tag_release_candidates(client, reg_model_name, experiment_name, 'rmse')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_ci.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ml-env]",
   "language": "python",
   "name": "conda-env-ml-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
